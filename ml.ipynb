{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47fa777-18b3-4ca7-b866-01c7aae59bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "seed = 42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # use gpu if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292c3167-357c-4bae-b899-df430071c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierLSTM(nn.Module):\n",
    "    def __init__(self, device, context_frames):\n",
    "        super(ClassifierLSTM, self).__init__()\n",
    "        self.device = device\n",
    "        self.context_frames = context_frames\n",
    "        self.lstm = nn.LSTM(32, 200).to(device)  # tactile\n",
    "        self.fc1 = nn.Linear(200, 40).to(device)\n",
    "        self.fc2 = nn.Linear(40, 1).to(device)\n",
    "        self.tan_activation = nn.Tanh().to(device)\n",
    "        self.relu_activation = nn.ReLU().to(device)\n",
    "        self.softmax_activation = nn.Softmax(dim=1).to(device) #we don't use this because BCE loss in pytorch automatically applies the the Sigmoid activation\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, tactiles):\n",
    "        batch_size__ = tactiles.shape[1]\n",
    "        hidden = (torch.zeros(1, batch_size__, 200, device=torch.device('cuda')), torch.zeros(1, batch_size__, 200, device=torch.device('cuda')))\n",
    "        lstm_out, self.hidden_lstm = self.lstm(tactiles, hidden)\n",
    "        lstm_out_drop = self.dropout(lstm_out[-1])\n",
    "        fc1_out = self.relu_activation(self.fc1(lstm_out_drop))\n",
    "        fc1_out_drop = self.dropout(fc1_out)\n",
    "        fc2_out = self.tan_activation(self.fc2(fc1_out_drop))\n",
    "\n",
    "        return fc2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d52e2bc-abf5-4001-aa64-90351ebfbabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, train_percentage, train_data_dir, batch_size, image_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.train_data_dir = train_data_dir\n",
    "        self.train_percentage = train_percentage\n",
    "        self.data_map = []\n",
    "        with open(train_data_dir + 'map.csv', 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                self.data_map.append(row)\n",
    "\n",
    "    def load_full_data(self):\n",
    "        dataset_train = FullDataSet(self.data_map, self.train_percentage, self.train_data_dir, self.image_size, train=True)\n",
    "        dataset_validate = FullDataSet(self.data_map, self.train_percentage, self.train_data_dir, self.image_size, validation=True)\n",
    "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "        train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=6, drop_last=True)\n",
    "        validation_loader = torch.utils.data.DataLoader(dataset_validate, batch_size=self.batch_size, shuffle=True, num_workers=6, drop_last=True)\n",
    "        self.data_map = []\n",
    "        return train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b0fc65-f255-4c41-b606-10da9b5bd27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullDataSet:\n",
    "    def __init__(self, data_map, train_percentage, train_data_dir, image_size, train=False, validation=False):\n",
    "        self.train_data_dir = train_data_dir\n",
    "        self.image_size = image_size\n",
    "        if train:\n",
    "            self.samples = data_map[1:int((len(data_map) * train_percentage))]\n",
    "        if validation:\n",
    "            self.samples = data_map[int((len(data_map) * train_percentage)): -1]\n",
    "        data_map = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        value = self.samples[idx]\n",
    "        slip_label = np.load(self.train_data_dir + value[4])\n",
    "        failure_label = np.load(self.train_data_dir + value[5])\n",
    "\n",
    "        if self.image_size == 0:\n",
    "            tactile_data = np.load(self.train_data_dir + value[0])\n",
    "            experiment_number = np.load(self.train_data_dir + value[1])\n",
    "            time_steps = np.load(self.train_data_dir + value[2])\n",
    "        else:\n",
    "            tactile_data = []\n",
    "            for image_name in np.load(self.train_data_dir + value[2]):\n",
    "                tactile_data.append(np.load(self.train_data_dir + image_name))\n",
    "            tactile_data = np.array(tactile_data)\n",
    "            experiment_number = np.load(self.train_data_dir + value[3])\n",
    "            time_steps = np.load(self.train_data_dir + value[4])\n",
    "\n",
    "        return [tactile_data.astype(np.float32), experiment_number, time_steps, slip_label, failure_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c98cd2cd-b66b-4d16-ae69-9b9bc39e5ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UniversalModelTrainer:\n",
    "    def __init__(self, model, criterion, image_size, model_save_path, model_name, epochs, batch_size,\n",
    "                 learning_rate, context_frames, sequence_length, train_percentage, validation_percentage, train_data_dir):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.context_frames = context_frames\n",
    "        self.sequence_length = sequence_length\n",
    "        self.train_percentage = train_percentage\n",
    "        self.validation_percentage = validation_percentage\n",
    "        self.model_name = model_name\n",
    "        self.model_save_path = model_save_path\n",
    "        self.model = model\n",
    "        self.image_size = image_size\n",
    "        self. train_data_dir = train_data_dir\n",
    "\n",
    "        BG = BatchGenerator(self.train_percentage, self.train_data_dir, self.batch_size, self.image_size)\n",
    "        self.train_full_loader, self.valid_full_loader = BG.load_full_data()\n",
    "\n",
    "        if criterion == \"L1\":\n",
    "            self.criterion = nn.L1Loss()\n",
    "        if criterion == \"L2\":\n",
    "            self.criterion = nn.MSELoss()\n",
    "        if criterion == \"BCEWithLogitsLoss\":\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def train_full_model(self):\n",
    "        best_training_loss = 100.0\n",
    "        training_val_losses = []\n",
    "        progress_bar = tqdm(range(0, self.epochs))\n",
    "        for epoch in progress_bar:\n",
    "            model_save = \"\"\n",
    "            self.train_loss = 0.0\n",
    "            self.val_loss = 0.0\n",
    "            self.train_acc = 0.0\n",
    "            self.val_acc = 0.0\n",
    "\n",
    "            # trainging\n",
    "            for index, batch_features in enumerate(self.train_full_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                slip_label = batch_features[3]\n",
    "                failure_label = batch_features[4]\n",
    "                slip_label = slip_label.to(device)\n",
    "                failure_label = failure_label.to(device)\n",
    "                tactile = torch.flatten(batch_features[0], start_dim=2).permute(1, 0, 2)[:, :, :32].to(device)\n",
    "                loss = self.run_batch(tactile, slip_label, train=True)            \n",
    "                train_max_index = index\n",
    "\n",
    "            # validation\n",
    "            for index, batch_features in enumerate(self.valid_full_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                slip_label = batch_features[3]\n",
    "                failure_label = batch_features[4]\n",
    "                slip_label = slip_label.to(device)\n",
    "                failure_label = failure_label.to(device)\n",
    "                tactile = torch.flatten(batch_features[0], start_dim=2)[:, :, :32].permute(1, 0, 2).to(device)\n",
    "                loss = self.run_batch(tactile, slip_label, validation=True)    \n",
    "                val_max_index = index\n",
    "\n",
    "            training_val_losses.append([self.train_loss/(train_max_index+1), self.val_loss/(val_max_index+1)])\n",
    "            np.save(self.model_save_path + \"train_val_losses\", np.array(training_val_losses))\n",
    "\n",
    "            # early stopping and saving:\n",
    "            if best_training_loss > self.val_loss/(val_max_index+1):\n",
    "                best_training_loss = self.val_loss/(val_max_index+1)\n",
    "                torch.save(self.model, self.model_save_path + self.model_name)\n",
    "                model_save = \"saved model\"\n",
    "\n",
    "            print(\"Training mean loss: {:.4f} || Validation mean loss: {:.4f} || Training mean Acc: {:.4f} || Validation mean Acc: {:.4f} || {}\".format(self.train_loss/(train_max_index+1), self.val_loss/(val_max_index+1), self.train_acc/(train_max_index+1), self.val_acc/(val_max_index+1), model_save))\n",
    "\n",
    "    def run_batch(self, tactile, slip_label, train=False, validation=False):\n",
    "        slip_predictions = self.model.forward(tactiles=tactile)  # Step 3. Run our forward pass.\n",
    "        loss = self.criterion(slip_predictions, slip_label.unsqueeze(1))\n",
    "        acc = self.binary_acc(slip_predictions, slip_label.unsqueeze(1))\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.train_loss += loss.item()\n",
    "            self.train_acc += acc.item()\n",
    "        elif validation:\n",
    "            self.val_loss += loss.item()\n",
    "            self.val_acc += acc.item()\n",
    "\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65d61b-d8cc-4b6d-9244-f70d5c172856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataset_path='data/'\n",
    "    model_save_path = dataset_path + 'train_out/'\n",
    "    train_data_dir = dataset_path + 'model/'\n",
    "\n",
    "    # unique save title:\n",
    "    model_save_path = model_save_path + \"model_\" + datetime.now().strftime(\"%d_%m_%Y_%H_%M/\")\n",
    "    os.mkdir(model_save_path)\n",
    "\n",
    "    epochs = 60\n",
    "    batch_size = 32\n",
    "    learning_rate = 1e-3\n",
    "    context_frames = 10\n",
    "    sequence_length = 10\n",
    "    train_percentage = 0.9\n",
    "    validation_percentage = 0.1\n",
    "    image_size = 0  # set to zero if linear data\n",
    "    criterion = \"BCEWithLogitsLoss\"\n",
    "    model_name = \"Baseline_LSTM\"\n",
    "    model = ClassifierLSTM(device=device, context_frames=context_frames)\n",
    "    model.to(device)\n",
    "\n",
    "    UMT = UniversalModelTrainer(model, criterion, image_size, model_save_path, model_name,\n",
    "                          epochs, batch_size, learning_rate, context_frames, sequence_length,\n",
    "                          train_percentage, validation_percentage, train_data_dir)\n",
    "    UMT.train_full_model()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
